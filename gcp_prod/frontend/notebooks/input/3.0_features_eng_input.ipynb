{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "205581ed-a7fb-45d4-9c93-eb67c648ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95186737-cbd2-44ee-ad56-89f916e705d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import prince\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027bc78f-9fd2-4ae3-af71-882233bb8dbf",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f3c7fa-503b-4b0a-9e27-7e960a48823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_eng(df, version):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if version == 'clustering':\n",
    "        df = df.drop(columns=['dist2','TransactionID'])\n",
    "    elif version == 'anomaly':\n",
    "        df = df.drop(columns=['dist2','customer_id','TransactionID'])\n",
    "    elif version == 'network':\n",
    "        df = df.drop(columns=['dist2'])\n",
    "    df = df.rename(columns={'id_31':'browser'})\n",
    "    df['P_emaildomain'] = df['P_emaildomain'].mask(df['P_emaildomain']=='gmail','gmail.com')\n",
    "    df['R_emaildomain'] = df['R_emaildomain'].mask(df['R_emaildomain']=='gmail','gmail.com')\n",
    "    df['id_30'] = df['id_30'].replace(\" \",\"_\",regex=True)\n",
    "    df['id_30'] = df['id_30'].str.replace(\".\",\"_\",regex=False)\n",
    "    df['browser'] = df['browser'].mask(df['browser'].str.contains('SM') | df['browser'].str.contains('ZTE'),'other')\n",
    "    df['browser'] = df['browser'].astype(str)\n",
    "    df['browser_enc'] = 'other'\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('ie'),'ie')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('safari'),'safari')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('edge'),'edge')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('firefox'),'firefox')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('android'),'android')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('Android'),'android')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('chrome'),'chrome')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('opera'),'opera')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('google'),'chrome')\n",
    "    df['browser_enc'] = df['browser_enc'].mask(df['browser'].str.contains('samsung'),'android')\n",
    "    df['DeviceType'] = df['DeviceType'].mask(df['browser']== 'ie 11.0 for tablet','tablet')\n",
    "    df = df.drop(columns='browser')\n",
    "    df['device_info'] = df['DeviceInfo'].replace(\"-\",\"_\",regex=True)\n",
    "    df['device_info2'] = df['device_info'].replace(\" \",\"_\",regex=True)\n",
    "    df['device_info'] = df['DeviceInfo'].replace(\"-\",\"_\",regex=True)\n",
    "    df['device_info2'] = df['device_info'].replace(\" \",\"_\",regex=True)\n",
    "    df['device_info3'] = df['device_info2'].str.split(\"_\").str[0]\n",
    "    df['device_info3'] = df['device_info3'].str.lower()\n",
    "    df['device_info_v4'] = 'other'\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(((df['device_info3']=='windows') | (df['device_info3']=='microsoft') | (df['device_info3']=='trident/7.0')),'windows')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(((df['device_info3']=='ios') | (df['device_info3']=='iphone')),'ios')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='macos','ios')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='blade','blade')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='lenovo','lenovo')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='redmi','redmi')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='pixel','pixel')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='android','android')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='macos','ios')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='alcatel','alcatel')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='nokia','nokia')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='asus','asus')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='oneplus','oneplus')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='zte','zte')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='macos','ios')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='hisense','hisense')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(df['device_info3']=='linux','linux')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask((df['device_info3'].str.contains(\"lg\") | (df['device_info3'].str.contains(\"nexus\"))),'lg')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(((df['device_info3'].str.contains(\"huawei\")) | (df['device_info3'].str.contains(\"hi6210sft\"))),'huawei')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(((df['device_info3']=='motog3') |(df['device_info3']=='moto')),'moto')\n",
    "    df['device_info_v4'] = df['device_info_v4'].mask(((df['device_info3']=='sm') |(df['device_info3']=='samsung')),'samsung')\n",
    "    df = df.drop(columns=['device_info','device_info2','device_info3','DeviceInfo'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382508d-67d1-44d6-b88a-21bb0fc024a2",
   "metadata": {},
   "source": [
    "# 1.0 Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f5445bc-6bb7-46fd-8591-7e87da23fd7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'app/output_files/train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapp/output_files/train.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m val \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp/output_files/val.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m>>> os.remove(\"./dummy.pkl\")\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py:651\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    642\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    643\u001b[0m             handle,\n\u001b[1;32m    644\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    648\u001b[0m         )\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'app/output_files/train.pkl'"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"datalake/train.pkl\")\n",
    "val = pd.read_pickle(\"datalake/val.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a613b77-4d1d-41f2-8352-7d665319aa6b",
   "metadata": {},
   "source": [
    "# 2.0 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9777ce7-7d4c-422c-8b4a-38cc63fc90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.write(\"Starting Features engineering for the training dataset...\")\n",
    "df = features_eng(df,'anomaly')\n",
    "st.write(\"Starting Features engineering for the validation dataset...\")\n",
    "val = features_eng(val,'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13b6c3-d1de-4965-9759-a4d83ec54721",
   "metadata": {},
   "source": [
    "# 3.0 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "780b7697-ef48-4661-820c-9bd57b911710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('datalake/train_eng.pkl')\n",
    "# val.to_pickle('datalake/val_eng.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f175f4-c792-4562-9119-c03a8199e65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd2f6d5425a7e7c90e9999f63918220ce4678e2578bc6cddf89f7206809257d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
